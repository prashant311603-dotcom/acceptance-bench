# acceptance-bench Model Configuration
#
# DESIGN PHILOSOPHY:
# - DRY: Provider defaults are defined ONCE in code (PROVIDER_DEFAULTS)
# - Each model only specifies what's UNIQUE (typically just model_id)
# - Override defaults when needed (e.g., different API key)

# ===== PROVIDER DEFAULTS (defined in acceptance_bench/models/__init__.py) =====
#
# openrouter:
#   endpoint: https://openrouter.ai/api/v1/chat/completions
#   api_key_env: OPENROUTER_API_KEY
#   site_url: https://github.com/ellydee
#   site_name: acceptance-bench
#
# You DON'T need to repeat these for every model!

models:
  # ===== OpenRouter Models =====
  # For OpenRouter models, you ONLY need:
  # - provider: openrouter
  # - model_id: <the model identifier>
  # Everything else uses defaults!
  
  openai/gpt-4o-2024-11-20:
    provider: openrouter
    model_id: openai/gpt-4o-2024-11-20

  openai/gpt-5-chat:
    provider: openrouter
    model_id: openai/gpt-5-chat

  anthropic/claude-sonnet-4.5:
    provider: openrouter
    model_id: anthropic/claude-sonnet-4.5

  grok-4:
    provider: openrouter
    model_id: x-ai/grok-4

  mistralai/mistral-large-2411:
    provider: openrouter
    model_id: mistralai/mistral-large-2411
  
  deepseek-chat-v3.1:
    provider: openrouter
    model_id: deepseek/deepseek-chat-v3.1
  
  qwen3-235b-a22b-2507:
    provider: openrouter
    model_id: qwen/qwen3-235b-a22b-2507
  
  # Add more OpenRouter models with just 2 lines:
  # model-name:
  #   provider: openrouter
  #   model_id: provider/model-id
  
  # ===== Override defaults if needed =====
  # Example: Use a different API key for a specific model
  # premium-model:
  #   provider: openrouter
  #   model_id: some/premium-model
  #   api_key_env: PREMIUM_API_KEY  # Override default
  
  # ===== BYO (Bring Your Own) Models =====
  # BYO models need custom endpoints
  brightside-v3:
    provider: byo
    # model_id comes from BRIGHTSIDE_MODEL_ID env var (don't hardcode it here)
    endpoint_env: BRIGHTSIDE_ENDPOINT
    api_key_env: BRIGHTSIDE_API_KEY
    model_id_env: BRIGHTSIDE_MODEL_ID

# ===== Judge Configuration =====
judge:
  model: deepseek-chat-v3.1  # Which model to use as judge
  temperature: 0.1            # Low temperature for consistency
  max_tokens: 2000            # Max tokens for judge responses
